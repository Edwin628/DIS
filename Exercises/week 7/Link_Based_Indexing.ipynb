{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link based ranking\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Exercise 1: Page rank  (Eigen-vector method)\n",
    "\n",
    "In the first exercise, we implement the Page Rank algorithm using Eigen vector method.\n",
    "\n",
    "\n",
    "### Goal:\n",
    "1. Implementing Page rank with Eigen-vector method.\n",
    "2. Testing the implemented method on a small Web with three pages (with four different link structures).\n",
    "\n",
    "### What you are learning in this exercise:\n",
    "1. Analyzing the output of PageRank for different link structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminaries:** If you want to normalize a vector to L1-norm or L2-norm, you can use `numpy` library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-norm of [1 2 3] is [0.16666667 0.33333333 0.5       ]\n",
      "L2-norm of [1 2 3] is [0.26726124 0.53452248 0.80178373]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "\n",
    "pr = np.array([1,2,3])\n",
    "print(\"L1-norm of {0} is {1}\".format(pr, pr / np.linalg.norm(pr,1)))\n",
    "print(\"L2-norm of {0} is {1}\".format(pr, pr / np.linalg.norm(pr,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "Please note that for this section, we are using the theoretical PageRank computation (without source of rank). See the slide \"Transition Matrix for Random Walker\" in the lecture notes. Columns of link matrix are from-vertex, rows of link matrix are to-vertex. We take the eigenvector with the largest eigenvalue.\n",
    "We only care about final ranking of the probability vector. You can choose the normalization (or not) of your choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 注意一下返回值, The eigenvalues will be returned as an array, and the eigenvectors will be returned as a matrix where each column is an eigenvector.\n",
    "2. 注意一下答案给的egienvalues的最大值是取绝对值的最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your code here\n",
    "def pagerank_eigen(L, R=None):\n",
    "    if R is None: # We might want to compute R outside this function to avoid recomputing large matrix\n",
    "        # Construct transition probability matrix from L\n",
    "        L_t = np.transpose(L)\n",
    "        L_t = np.array(L_t) # 将matrix转换成array进行操作会方便点\n",
    "        R_t = [item / np.linalg.norm(item,1) for item in L_t]\n",
    "        R = np.transpose(R_t)\n",
    "        print(L_t.shape[0])\n",
    "        print(L_t.shape[1])\n",
    "    # Compute eigen-vectors and eigen-values of R\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(R)\n",
    "    # Take the eigen-vector with maximum eigven-value\n",
    "    # Find the index of the maximum eigenvalue\n",
    "    # Select the corresponding eigenvector\n",
    "    \n",
    "    # p = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "    p = np.absolute(eigenvectors[:,np.argmax(np.absolute(eigenvalues))])\n",
    "    return (R,p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.matrix和普通的list、array一些不一样,L[0][1]不能访问matrix的元素，要用L[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "L=[[0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]]\n",
      "R=[[0.  0.5 0.5]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "p=[0.57735027 0.57735027 0.57735027]\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample case, e.g.\n",
    "L = np.matrix([\n",
    "    [0,1,1], \n",
    "    [1,0,1], \n",
    "    [1,1,0]\n",
    "])\n",
    "R,p = pagerank_eigen(L)\n",
    "print(\"L={0}\\nR={1}\\np={2}\".format(L,R,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Exercise 2: Page rank  (Iterative method)\n",
    "\n",
    "In the second exercise, we implement the Page Rank algorithm with an iterative approach.\n",
    "\n",
    "\n",
    "### Goal:\n",
    "1. Implementing Page rank with the iterative method.\n",
    "2. Reading the `ca-GrQc.txt` dataset and constructing its link matrix\n",
    "3. Testing the implemented algorithm on the constructed link matrix\n",
    "4. comparing the run-time of iterative method and eigen-vector method.\n",
    "\n",
    "### What you are learning in this exercise:\n",
    "1. Benefits of the iterative approach over eigen-vector method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigen-vector method has some numerical issues (when computing eigen-vector) and not scalable with large datasets.\n",
    "\n",
    "We will apply the iterative method in the slide \"Practical Computation of PageRank\" of the lecture.\n",
    "\n",
    "Dataset for practice: https://snap.stanford.edu/data/ca-GrQc.html. It is available within the same paths of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.matrix([\n",
    "    [0,1,1], \n",
    "    [1,0,1], \n",
    "    [1,1,0]\n",
    "])\n",
    "np.multiply(L, 1 / np.sum(L,axis=0))\n",
    "L.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_iterative(L, R=None):\n",
    "    if R is None:  # We might want to compute R outside this function to avoid recomputing large matrix\n",
    "        R = np.multiply(L, 1 / np.sum(L,axis=0)) # multiply是elementwise的操作，等同于 *\n",
    "    #todo\n",
    "    # R = pagerank_eigen(L,R)\n",
    "    N = L.shape[0]\n",
    "    e = np.ones(shape=(N,1))\n",
    "    q = 0.9\n",
    "\n",
    "    p = e\n",
    "    delta = 1\n",
    "    epsilon = 0.001\n",
    "    i = 0\n",
    "    while delta > epsilon:\n",
    "        p_prev = p\n",
    "        p = np.dot(q,np.dot(R,p_prev)) \n",
    "        p = p + np.dot((1-q)/N,e)\n",
    "        delta = np.linalg.norm(p - p_prev,1)\n",
    "        i += 1\n",
    "\n",
    "    print(\"Converged after {0} iterations. Ranking vector: p={1}\".format(i, p[:,0]))\n",
    "    return R,p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct link matrix from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "a = \"1  2\\n\"\n",
    "re.split(r'\\s+', a)\n",
    "a.split()\n",
    "re.split(r'\\s+', a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 开始无法确定L的size，所以说一定要读两次文件，第一次用来获取edge的index的一些范围，然后再确定具体内容\n",
    "2. 因为L的默认是0-N，所以一定要存储对应的index值是多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5242\n",
      "[3466, 937, 5233]\n"
     ]
    }
   ],
   "source": [
    "# Construct link matrix from file\n",
    "n_nodes = 0 # number of nodes in the dataset\n",
    "nodes_idx = dict() #Since the nodeIDs are not from 0 to N we need to build an index of nodes\n",
    "nodes = [] #We also want to store nodeIDs to return the result of ranking vector\n",
    "\n",
    "with open(\"ca-GrQc.txt\") as f:\n",
    "    # Fill in your code\n",
    "    for line in f:\n",
    "        # Check if the line starts with \"#\"\n",
    "        if not line.startswith(\"#\"):\n",
    "            from_idx, to_idx = line.split() #虽然返回的是list，但是只要是个数对应，还是可以直接赋值的\n",
    "            from_idx, to_idx = int(from_idx), int(to_idx)\n",
    "            if from_idx not in nodes_idx:\n",
    "                nodes_idx[from_idx] = n_nodes\n",
    "                nodes.append(from_idx)\n",
    "                n_nodes += 1\n",
    "            if to_idx not in nodes:\n",
    "                nodes_idx[to_idx] = n_nodes\n",
    "                n_nodes += 1\n",
    "                nodes.append(to_idx)\n",
    "\n",
    "print(n_nodes)\n",
    "\n",
    "L = np.zeros((n_nodes,n_nodes))\n",
    "\n",
    "with open(\"ca-GrQc.txt\") as f:\n",
    "    # Fill in your code\n",
    "    for line in f:\n",
    "        # Check if the line starts with \"#\"\n",
    "        if not line.startswith(\"#\"):\n",
    "            from_idx, to_idx = line.split() #虽然返回的是list，但是只要是个数对应，还是可以直接赋值的\n",
    "            from_idx, to_idx = int(from_idx), int(to_idx)\n",
    "            L[nodes_idx[from_idx],nodes_idx[to_idx]] = 1\n",
    "\n",
    "print(nodes[:3])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the run-time of eigen-vector and iterative methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will see that eigen-vector method is slow and has some numerical issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we pre-compute the R matrix and pass it as argument to Page rank algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.2   0.5   ... 0.    0.    0.   ]\n",
      " [0.125 0.    0.    ... 0.    0.    0.   ]\n",
      " [0.125 0.    0.    ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.    0.    0.    ... 0.    0.5   0.5  ]\n",
      " [0.    0.    0.    ... 0.5   0.    0.5  ]\n",
      " [0.    0.    0.    ... 0.5   0.5   0.   ]]\n"
     ]
    }
   ],
   "source": [
    "R = np.multiply(L, 1 / np.sum(L,axis=0))  # note that this doesn't handle zero columns\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 56.280269145965576 seconds ---\n",
      "Ranking vector: p=[1.85653750e-18 7.30886398e-18 1.32051427e-18 ... 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# Run PageRank\n",
    "R,p = pagerank_eigen(L, R)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Ranking vector: p={0}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 128 iterations. Ranking vector: p=[2.91315639e-04 1.88382754e-04 8.39741651e-05 ... 1.92156702e-04\n",
      " 1.92156702e-04 1.92156702e-04]\n",
      "--- 1.4321448802947998 seconds ---\n",
      "Ranking vector: p=[2.91315639e-04 1.88382754e-04 8.39741651e-05 ... 1.92156702e-04\n",
      " 1.92156702e-04 1.92156702e-04]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Run PageRank\n",
    "R, p = pagerank_iterative(L, R)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Ranking vector: p={0}\".format(p[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's extract top-k nodes from the ranking vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5242, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 nodes: [14265 13801 13929]\n",
      "Their scores: [0.00144951 0.00141553 0.00138011]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array(p[:,0])\n",
    "k = 3\n",
    "#todo index of top-k nodes\n",
    "k_idx = np.argsort(arr)[::-1][:k] #注意argmax只取了最大值，而且argsort是从小到大\n",
    "print(\"Top-{0} nodes: {1}\".format(k, np.array(nodes)[k_idx]))\n",
    "print(\"Their scores: {0}\".format(arr[k_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Exercise 3: Ranking Methodology  (Hard)\n",
    "This exercise is theoretical and you don't need to write code for it:\n",
    "\n",
    "1. Give a directed graph, as small as possible, satisfying all the properties mentioned below:\n",
    "\n",
    "    1. There exists a path from node i to node j for all nodes i,j in the directed\n",
    "graph. Recall, with this property the jump to an arbitrary node in PageRank\n",
    "is not required, so that you can set q = 1 (refer lecture slides).\n",
    "\n",
    "    2. HITS authority ranking and PageRank ranking of the graph nodes are different.\n",
    "\n",
    "2. Give intuition/methodology on how you constructed such a directed graph with\n",
    "the properties described in (a).\n",
    "\n",
    "3. Are there specific graph structures with arbitrarily large instances where PageRank\n",
    "ranking and HITS authority ranking are the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Exercise 4: Hub and Authority\n",
    "\n",
    "In the last exercise, we implement the (iterative) HITS algorithm to calculate the authority and hub scores for this graph.\n",
    "\n",
    "\n",
    "### Goal:\n",
    "1. Implementing HITS algorithm.\n",
    "2. Identifying the best authority and hub nodes for a small graph (part `a`) as well as the `ca-GrQc.txt` dataset (part `b`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### a)\n",
    "\n",
    "Let the adjacency matrix for a graph of four vertices ($n_1$ to $n_4$) be\n",
    "as follows:\n",
    "\n",
    "$\n",
    "A =\n",
    "  \\begin{bmatrix}\n",
    "\t0 & 1 & 1 & 1  \\\\\n",
    "\t0 & 0 & 1 & 1 \\\\\n",
    "\t1 & 0 & 0 & 1 \\\\\n",
    "\t0 & 0 & 0 & 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "\n",
    "Calculate the authority and hub scores for this graph using the\n",
    "HITS algorithm with k = 6, and identify the best authority and\n",
    "hub nodes. (A non-zero element $A_{ij}$ indicates an edge from $i$ to $j$.)\n",
    "\n",
    "### b)\n",
    "Apply the HITS algorithm to the `ca-GrQc.txt` dataset (the same dataset as for the `Exercise 2`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** We follow the slide \"HITS algorithm\" in the lecture. **Denote $x$ as authority vector and $y$ as hub vector**. You can use matrix multiplication for the update steps in the slide \"Convergence of HITS\". Note that rows of adjacency matrix is from-vertex and columns of adjacency matrix is to-vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是最原始最蠢的方法,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can implement your code following this template.\n",
    "def hits_iterative(A, k=10):\n",
    "    N = A.shape[0]\n",
    "    x0, y0 = 1 / (N**0.5) * np.ones(N), 1 / (N**0.5) * np.ones(N)\n",
    "    xprev, yprev = x0, y0\n",
    "    \n",
    "    # For advanced exercise: define a convergence condition instead of k iterations\n",
    "    for l in range(0,k):\n",
    "        x = xprev\n",
    "        y = yprev\n",
    "        x = [np.dot(y,col_A) for col_A in np.transpose(A)]\n",
    "        y = [np.dot(x,row_A) for row_A in np.array(A)]\n",
    "        xprev = x/np.linalg.norm(x,2)\n",
    "        yprev = y/np.linalg.norm(y,2)\n",
    "        \n",
    "    return xprev, yprev"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 有多个条件就用while循环\n",
    "2. while记得要给l+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can implement your code following this template.\n",
    "def hits_iterative(A, k=10):\n",
    "    N = A.shape[0]\n",
    "    x0, y0 = 1 / (N**0.5) * np.ones(N), 1 / (N**0.5) * np.ones(N)\n",
    "    xprev, yprev = x0, y0\n",
    "    delta1 = delta2 = 1\n",
    "    epsilon = 0.001 # We can strictly check for convergence rate of HITS algorithm\n",
    "    l = 0\n",
    "    # For advanced exercise: define a convergence condition instead of k iterations\n",
    "    while l < k and delta1 > epsilon and delta2 > epsilon: #  循环别忘记增加l啊\n",
    "        #x = np.matmul(yprev,A)\n",
    "        y = np.transpose(np.matmul(A,xprev))\n",
    "        x = np.matmul(y,A)\n",
    "        # y = np.matmul(A,x) 甚至上面都不用加transpose\n",
    "        x = x/np.linalg.norm(x,2)\n",
    "        delta1 = np.linalg.norm(x-xprev,1)\n",
    "        y = y/np.linalg.norm(y,2)\n",
    "        delta2 = np.linalg.norm(y-yprev,1)\n",
    "        xprev = x\n",
    "        yprev = y\n",
    "        l += 1\n",
    "    print(\"Ran a total of {0} iterations with the convergence rate delta1, delta2={1},{2}\".format(l, delta1, delta2))\n",
    "    return xprev, yprev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part `a` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran a total of 6 iterations with the convergence rate delta1, delta2=0.0007253933456335127,0.0003337175283154581\n",
      "Result using iterative method:\n",
      " Authoriy vector x=[0.16854458 0.27251688 0.49793945 0.8058434 ]\n",
      " Hub vector y=[0.65546229 0.5421434  0.4051733  0.33508853]\n"
     ]
    }
   ],
   "source": [
    "A=np.array([\n",
    "    [0, 1, 1, 1], \n",
    "    [0, 0, 1, 1], \n",
    "    [1, 0, 0, 1],\n",
    "    [0, 0, 0, 1],\n",
    "])\n",
    "x, y = hits_iterative(A, k=6)\n",
    "print(\"Result using iterative method:\\n Authoriy vector x={0}\\n Hub vector y={1}\".format(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part `b` dataset\n",
    "You can reuse the link matrix $L$ (from Exercise 2) to compute the adjacency matrix $A$ of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.transpose(L) # your code here\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run HITS algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran a total of 22 iterations with the convergence rate delta1, delta2=0.0008757061781100327,0.0010491474133458398\n",
      "Result using iterative method:\n",
      " Authoriy vector x=[3.48948782e-05 1.45965227e-05 6.68131191e-06 ... 2.07766184e-61\n",
      " 2.07766184e-61 2.07766184e-61]\n",
      " Hub vector y=[3.48948790e-05 1.45965251e-05 6.68131268e-06 ... 4.73879981e-60\n",
      " 4.73879981e-60 4.73879981e-60]\n"
     ]
    }
   ],
   "source": [
    "x, y = hits_iterative(A, 100)\n",
    "print(\"Result using iterative method:\\n Authoriy vector x={0}\\n Hub vector y={1}\".format(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "0adb3f5f654606e41dbdfd3bbda90ddbd940f914bbda17aa2fe6222e3a406da4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
