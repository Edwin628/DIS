{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Exercise: Latent Semantic Indexing\n",
    "In this exercise we would learn about Latent Semantic Indexing (LSI) based retrieval models.\n",
    "\n",
    "### Goal:\n",
    "- Implement a search engine using LSI\n",
    "- Visualize the LSI concepts\n",
    "- Compare the retrieval results with scikit vector space retrieval method (as an oracle)\n",
    "\n",
    "### What you are learning in this exercise:\n",
    "1. Learn more about LSI approach\n",
    "2. How retrieval results can be different in LSI and vector space retrieval models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1: Implement Latent Semantic Indexing (LSI)\n",
    "### 1.1 Read the corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aibin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/aibin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Required libraries.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import math\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')).union(set(stopwords.words('french')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    '''Reads corpus from files.'''\n",
    "    \n",
    "    documents = []\n",
    "    orig_docs = []\n",
    "    DIR = './'\n",
    "    tknzr = TweetTokenizer()\n",
    "    with open(\"epfldocs.txt\", encoding = \"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "    for text in content:\n",
    "        orig_docs.append(text)\n",
    "        # split into words\n",
    "        tokens = tknzr.tokenize(text)\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        # remove remaining tokens that are not alphabetic\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        # filter out stop words\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "\n",
    "        documents.append(' '.join(words))\n",
    "    return documents, orig_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, orig_docs = read_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1075"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Build the vocabulary by selecting top-k frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary_frequency(corpus, vocab_len):\n",
    "    '''Select top-k (k = vocab_len) words in term of frequencies as vocabulary'''\n",
    "    \n",
    "    count = {}\n",
    "    for document in corpus:\n",
    "        for word in document.split():\n",
    "            if word in count:\n",
    "                count[word] += 1\n",
    "            else:\n",
    "                count[word] = 1\n",
    "    \n",
    "    sorted_count_by_freq = sorted(count.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "    vocabulary = [x[0] for x in sorted_count_by_freq[:vocab_len]]\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_freq = create_vocabulary_frequency(documents, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epfl',\n",
       " 'epflen',\n",
       " 'via',\n",
       " 'new',\n",
       " 'lausanne',\n",
       " 'switzerland',\n",
       " 'vdtech',\n",
       " 'research',\n",
       " 'swiss',\n",
       " 'science',\n",
       " 'students',\n",
       " 'innovation',\n",
       " 'first',\n",
       " 'martinvetterli',\n",
       " 'day',\n",
       " 'solar',\n",
       " 'great',\n",
       " 'open',\n",
       " 'unil',\n",
       " 'data',\n",
       " 'technology',\n",
       " 'learning',\n",
       " 'thanks',\n",
       " 'ethen',\n",
       " 'work',\n",
       " 'prof',\n",
       " 'today',\n",
       " 'startup',\n",
       " 'talk',\n",
       " 'see',\n",
       " 'days',\n",
       " 'next',\n",
       " 'congrats',\n",
       " 'one',\n",
       " 'good',\n",
       " 'suisse',\n",
       " 'researchers',\n",
       " 'campus',\n",
       " 'center',\n",
       " 'time',\n",
       " 'eth',\n",
       " 'energy',\n",
       " 'robots',\n",
       " 'join',\n",
       " 'us',\n",
       " 'epflcampus',\n",
       " 'cc',\n",
       " 'made',\n",
       " 'lab',\n",
       " 'dgtswitzerland',\n",
       " 'world',\n",
       " 'brain',\n",
       " 'robot',\n",
       " 'looking',\n",
       " 'meeting',\n",
       " 'people',\n",
       " 'drone',\n",
       " 'get',\n",
       " 'future',\n",
       " 'human',\n",
       " 'mooc',\n",
       " 'perovskite',\n",
       " 'could',\n",
       " 'epflenac',\n",
       " 'free',\n",
       " 'robotics',\n",
       " 'event',\n",
       " 'marcelsalathe',\n",
       " 'conference',\n",
       " 'proud',\n",
       " 'light',\n",
       " 'workshop',\n",
       " 'forward',\n",
       " 'week',\n",
       " 'school',\n",
       " 'der',\n",
       " 'president',\n",
       " 'universities',\n",
       " 'design',\n",
       " 'read',\n",
       " 'im',\n",
       " 'university',\n",
       " 'scientists',\n",
       " 'watch',\n",
       " 'cours',\n",
       " 'team',\n",
       " 'article',\n",
       " 'last',\n",
       " 'top',\n",
       " 'take',\n",
       " 'exciting',\n",
       " 'machine',\n",
       " 'best',\n",
       " 'start',\n",
       " 'excited',\n",
       " 'tomorrow',\n",
       " 'even',\n",
       " 'international',\n",
       " 'find',\n",
       " 'machinelearning',\n",
       " 'tech',\n",
       " 'epflevents',\n",
       " 'place',\n",
       " 'merci',\n",
       " 'working',\n",
       " 'oscience',\n",
       " 'f√ºr',\n",
       " 'cells',\n",
       " 'w',\n",
       " 'come',\n",
       " 'digital',\n",
       " 'award',\n",
       " 'datascience',\n",
       " 'part',\n",
       " 'architecture',\n",
       " 'paper',\n",
       " 'available',\n",
       " '√©tudiants',\n",
       " 'video',\n",
       " 'years',\n",
       " 'und',\n",
       " 'congratulations',\n",
       " 'latest',\n",
       " 'cancer',\n",
       " 'projet',\n",
       " 'possible',\n",
       " 'two',\n",
       " 'mars',\n",
       " 'also',\n",
       " 'appliedmldays',\n",
       " 'smart',\n",
       " 'unigenews',\n",
       " 'quantum',\n",
       " 'drones',\n",
       " 'von',\n",
       " 'participants',\n",
       " 'really',\n",
       " 'help',\n",
       " 'professor',\n",
       " 'walk',\n",
       " 'happy',\n",
       " 'water',\n",
       " 'meet',\n",
       " 'swisscytometry',\n",
       " 'way',\n",
       " 'system',\n",
       " 'many',\n",
       " 'says',\n",
       " 'education',\n",
       " 'jacques',\n",
       " 'using',\n",
       " 'understand',\n",
       " 'zu',\n",
       " 'go',\n",
       " 'opportunity',\n",
       " 'activity',\n",
       " 'conf√©rence',\n",
       " 'youtube',\n",
       " 'bien',\n",
       " 'global',\n",
       " 'study',\n",
       " 'show',\n",
       " 'formation',\n",
       " 'trust',\n",
       " 'nice',\n",
       " 'group',\n",
       " 'lecture',\n",
       " 'applied',\n",
       " 'ml',\n",
       " 'cseminfo',\n",
       " 'faire',\n",
       " 'fa√ßade',\n",
       " 'programme',\n",
       " 'program',\n",
       " 'think',\n",
       " 'need',\n",
       " 'artificial',\n",
       " 'engineering',\n",
       " 'like',\n",
       " 'unifr',\n",
       " 'cool',\n",
       " 'tool',\n",
       " 'vr',\n",
       " 'director',\n",
       " 'zurich',\n",
       " 'public',\n",
       " 'developed',\n",
       " 'topic',\n",
       " 'space',\n",
       " 'eucommission',\n",
       " 'impact',\n",
       " 'french',\n",
       " 'largest',\n",
       " 'clean',\n",
       " 'presenting',\n",
       " '√©tudiant',\n",
       " 'cest',\n",
       " 'night',\n",
       " 'apply',\n",
       " 'startups',\n",
       " 'look',\n",
       " 'sdscdatascience',\n",
       " 'internet',\n",
       " 'year',\n",
       " 'cell',\n",
       " 'virtual',\n",
       " 'mieux',\n",
       " 'improve',\n",
       " 'rolex',\n",
       " 'comment',\n",
       " 'epflpark',\n",
       " 'deadline',\n",
       " 'recherche',\n",
       " 'fantastic',\n",
       " 'guide',\n",
       " 'aihealth',\n",
       " 'march',\n",
       " 'sv',\n",
       " 'disease',\n",
       " 'epflsv',\n",
       " 'phd',\n",
       " 'biology',\n",
       " 'development',\n",
       " 'house',\n",
       " 'dubochet',\n",
       " 'france',\n",
       " 'launch',\n",
       " 'less',\n",
       " 'discussion',\n",
       " 'potential',\n",
       " 'interview',\n",
       " 'plus',\n",
       " 'make',\n",
       " 'openscience',\n",
       " 'online',\n",
       " 'edtech',\n",
       " 'rolexlearningcenter',\n",
       " 'access',\n",
       " 'dark',\n",
       " 'venturelabch',\n",
       " 'library',\n",
       " 'dont',\n",
       " 'register',\n",
       " 'lead',\n",
       " 'neige',\n",
       " 'copenhagen',\n",
       " 'green',\n",
       " 'novel',\n",
       " 'das',\n",
       " 'weekend',\n",
       " 'single',\n",
       " 'noir',\n",
       " 'ever',\n",
       " 'master',\n",
       " 'num√©rique',\n",
       " 'learn',\n",
       " 'real',\n",
       " 'gen√®ve',\n",
       " 'robotic',\n",
       " 'young',\n",
       " 'model',\n",
       " 'dun',\n",
       " 'chuvlausanne',\n",
       " 'apr√®s',\n",
       " 'want',\n",
       " 'based',\n",
       " 'present',\n",
       " 'airbnb',\n",
       " '√ßa',\n",
       " 'experience',\n",
       " 'competition',\n",
       " 'efficiency',\n",
       " 'thesis',\n",
       " 'high',\n",
       " 'blue',\n",
       " 'business',\n",
       " 'funding',\n",
       " 'hesso',\n",
       " 'jai',\n",
       " 'brjsa',\n",
       " 'centre',\n",
       " 'nouveau',\n",
       " 'thymioii',\n",
       " 'would',\n",
       " 'agepoly',\n",
       " 'million',\n",
       " 'inside',\n",
       " 'sciences',\n",
       " 'final',\n",
       " 'materials',\n",
       " 'deeplearning',\n",
       " 'nobelprize',\n",
       " 'winner',\n",
       " 'valais',\n",
       " 'film',\n",
       " 'nature',\n",
       " 'uzhnews',\n",
       " 'sxswiss',\n",
       " 'federal',\n",
       " 'institutes',\n",
       " 'welcome',\n",
       " 'forumepfl',\n",
       " 'support',\n",
       " 'zotero',\n",
       " 'intelligence',\n",
       " 'livre',\n",
       " 'towards',\n",
       " 'society',\n",
       " 'rt',\n",
       " 'offers',\n",
       " 'understanding',\n",
       " 'poster',\n",
       " 'workshops',\n",
       " 'luck',\n",
       " 'neuroscience',\n",
       " 'quality',\n",
       " 'successful',\n",
       " 'cytometry',\n",
       " 'polytechnique',\n",
       " 'systems',\n",
       " 'strong',\n",
       " 'among',\n",
       " 'still',\n",
       " 'security',\n",
       " 'information',\n",
       " 'matter',\n",
       " 'generation',\n",
       " 'apprendre',\n",
       " 'champsnight',\n",
       " 'police',\n",
       " 'love',\n",
       " 'technologies',\n",
       " 'hessovalais',\n",
       " 'stop',\n",
       " 'alzheimers',\n",
       " 'ceremony',\n",
       " 'mission',\n",
       " 'become',\n",
       " 'innovaud',\n",
       " 'sant√©',\n",
       " 'avalanche',\n",
       " 'full',\n",
       " 'snow',\n",
       " 'danish',\n",
       " 'installs',\n",
       " 'food',\n",
       " 'course',\n",
       " 'bigdata',\n",
       " 'level',\n",
       " 'chemistry',\n",
       " 'collaboration',\n",
       " 'frederickaplan',\n",
       " 'die',\n",
       " 'ready',\n",
       " 'colleagues',\n",
       " 'art',\n",
       " 'swissnexsf',\n",
       " 'session',\n",
       " 'tour',\n",
       " 'code',\n",
       " 'analysis',\n",
       " 'leurs',\n",
       " 'thank',\n",
       " 'mobility',\n",
       " 'cybersecurityday',\n",
       " 'impressive',\n",
       " 'well',\n",
       " 'immune',\n",
       " 'excellent',\n",
       " 'back',\n",
       " 'visit',\n",
       " '√©tudes',\n",
       " 'making',\n",
       " 'projets',\n",
       " 'sure',\n",
       " 'applications',\n",
       " 'villes',\n",
       " 'epfllibrary',\n",
       " 'save',\n",
       " 'date',\n",
       " 'site',\n",
       " 'monde',\n",
       " 'reality',\n",
       " 'venture',\n",
       " 'former',\n",
       " 'power',\n",
       " 'market',\n",
       " 'nrel',\n",
       " 'record',\n",
       " 'hackathon',\n",
       " 'sign',\n",
       " 'projects',\n",
       " 'talking',\n",
       " 'old',\n",
       " 'done',\n",
       " 'al',\n",
       " 'develop',\n",
       " 'control',\n",
       " 'openfood',\n",
       " 'uzhnewsen',\n",
       " 'discover',\n",
       " 'edacyhq',\n",
       " 'invest',\n",
       " 'important',\n",
       " 'travail',\n",
       " 'si',\n",
       " 'quand',\n",
       " 'wef',\n",
       " 'attend',\n",
       " 'laboratory',\n",
       " 'fmondada',\n",
       " 'swsx',\n",
       " 'moocs',\n",
       " 'traces',\n",
       " 'martian',\n",
       " 'biological',\n",
       " 'meteorite',\n",
       " 'bravo',\n",
       " 'long',\n",
       " 'geneva',\n",
       " 'takes',\n",
       " 'health',\n",
       " 'life',\n",
       " 'early',\n",
       " 'april',\n",
       " 'main',\n",
       " 'city',\n",
       " 'aujourdhui',\n",
       " 'demain',\n",
       " 'epfls',\n",
       " 'areas',\n",
       " 'vaud',\n",
       " 'mechanics',\n",
       " 'wave',\n",
       " 'particle',\n",
       " 'lepfl',\n",
       " 'sich',\n",
       " 'chf',\n",
       " 'interaction',\n",
       " 'highlights',\n",
       " 'student',\n",
       " 'rlerignier',\n",
       " 'norme',\n",
       " 'tous',\n",
       " 'indeed',\n",
       " 'tumuenchen',\n",
       " 'hand',\n",
       " 'tuned',\n",
       " 'speakers',\n",
       " 'deep',\n",
       " 'psf',\n",
       " 'algorithms',\n",
       " 'digitalhealth',\n",
       " 'exposition',\n",
       " 'play',\n",
       " 'spinoff',\n",
       " 'know',\n",
       " 'rrl',\n",
       " 'dr',\n",
       " 'michael',\n",
       " 'panel',\n",
       " 'point',\n",
       " 'solutions',\n",
       " 'without',\n",
       " 'nanostructures',\n",
       " 'use',\n",
       " 'timeshighered',\n",
       " 'opportunities',\n",
       " 'inspired',\n",
       " 'wikipedia',\n",
       " 'studies',\n",
       " 'danger',\n",
       " 'slf',\n",
       " 'innovative',\n",
       " 'challenge',\n",
       " 'ia',\n",
       " 'eawagresearch',\n",
       " 'bibliotheque',\n",
       " 'tr√®s',\n",
       " 'aging',\n",
       " 'mit',\n",
       " 'alumni',\n",
       " 'unigeen',\n",
       " 'stem',\n",
       " 'much',\n",
       " 'sneedition',\n",
       " 'iso',\n",
       " 'february',\n",
       " 'cern',\n",
       " 'eurekalert',\n",
       " 'music',\n",
       " 'call',\n",
       " 'starts',\n",
       " 'intel',\n",
       " 'lets',\n",
       " 'privacy',\n",
       " 'lieu',\n",
       " 'info',\n",
       " 'page',\n",
       " 'fish',\n",
       " 'optical',\n",
       " 'may',\n",
       " 'amazing',\n",
       " 'europe',\n",
       " 'prize',\n",
       " 'bacterial',\n",
       " 'around',\n",
       " 'social',\n",
       " 'nberpubs',\n",
       " 'letemps',\n",
       " 'check',\n",
       " 'lesoepfl',\n",
       " 'club',\n",
       " 'scicomm',\n",
       " 'entre',\n",
       " 'happening',\n",
       " 'give',\n",
       " 'software',\n",
       " 'big',\n",
       " 'building',\n",
       " 'going',\n",
       " 'modeling',\n",
       " 'method',\n",
       " 'cet',\n",
       " 'january',\n",
       " 'soft',\n",
       " 'lake',\n",
       " 'dna',\n",
       " 'nccrrobotics',\n",
       " 'premier',\n",
       " 'network',\n",
       " 'achieve',\n",
       " 'sustainability',\n",
       " 'exosquelette',\n",
       " 'created',\n",
       " 'published',\n",
       " 'swisstechepfl',\n",
       " 'tonight',\n",
       " 'host',\n",
       " 'book',\n",
       " 'question',\n",
       " 'nexus',\n",
       " 'opensource',\n",
       " 'datadriven',\n",
       " 'girls',\n",
       " 'wslresearch',\n",
       " 'entrepreneurship',\n",
       " 'jobs',\n",
       " 'ask',\n",
       " 'speaking',\n",
       " 'silicon',\n",
       " 'prix',\n",
       " 'heart',\n",
       " 'epflartlab',\n",
       " 'man',\n",
       " 'opendata',\n",
       " 'computer',\n",
       " 'edacy',\n",
       " 'digitaltrust',\n",
       " 'ethrat',\n",
       " 'atelier',\n",
       " 'etc',\n",
       " 'ligne',\n",
       " 'keep',\n",
       " 'hosted',\n",
       " 'live',\n",
       " 'engineers',\n",
       " 'interesting',\n",
       " 'blockchain',\n",
       " 'fintech',\n",
       " 'robotique',\n",
       " 'humans',\n",
       " 'media',\n",
       " 'experts',\n",
       " 'mind',\n",
       " 'institute',\n",
       " 'symposium',\n",
       " 'summer',\n",
       " 'complexes',\n",
       " 'computational',\n",
       " 'presents',\n",
       " 'plenty',\n",
       " 'presented',\n",
       " 'missing',\n",
       " 'mobile',\n",
       " 'window',\n",
       " 'monitoring',\n",
       " 'process',\n",
       " 'd√©but',\n",
       " 'septembre',\n",
       " 'ein',\n",
       " 'effyvayena',\n",
       " 'sxsw',\n",
       " 'aussi',\n",
       " 'solaire',\n",
       " 'thing',\n",
       " 'another',\n",
       " 'else',\n",
       " 'offer',\n",
       " 'pratique',\n",
       " 'csl',\n",
       " 'enjeux',\n",
       " 'artificielle',\n",
       " 'iot',\n",
       " 'd√©couvrez',\n",
       " 'industrial',\n",
       " 'davos',\n",
       " 'interactions',\n",
       " 'transportation',\n",
       " 'alahi',\n",
       " 'travers',\n",
       " 'sans',\n",
       " 'policy',\n",
       " 'according',\n",
       " 'tueindhoven',\n",
       " 'used',\n",
       " 'naturecomms',\n",
       " 'super',\n",
       " 'stay',\n",
       " 'violainesee',\n",
       " 'cciliv',\n",
       " 'images',\n",
       " 'test',\n",
       " 's√©curit√©',\n",
       " 'able',\n",
       " 'medtech',\n",
       " 'p',\n",
       " 'measuring',\n",
       " 'swissedtechcollider',\n",
       " 'line',\n",
       " 'lives',\n",
       " 'mal',\n",
       " 'ecole',\n",
       " 'f√©d√©rale',\n",
       " 'feb',\n",
       " 'operations',\n",
       " 'size',\n",
       " 'virtualreality',\n",
       " 'environments',\n",
       " 'natural',\n",
       " 'bad',\n",
       " 'ist',\n",
       " 'partners',\n",
       " 'yunus',\n",
       " 'makes',\n",
       " 'darker',\n",
       " 'thought',\n",
       " 'darkmatter',\n",
       " 'hubble',\n",
       " 'astronomy',\n",
       " 'presentation',\n",
       " 'hopitauxunige',\n",
       " 'training',\n",
       " 'storage',\n",
       " 'professeur',\n",
       " 'besoin',\n",
       " 'population',\n",
       " 'uefa',\n",
       " 'healthy',\n",
       " 'mitochondria',\n",
       " 'someone',\n",
       " 'concept',\n",
       " 'travel',\n",
       " 'thomas',\n",
       " 'claude',\n",
       " 'nicollier',\n",
       " 'european',\n",
       " 'dsmeu',\n",
       " 'factory',\n",
       " 'masschallengech',\n",
       " 'japan',\n",
       " 'rts',\n",
       " 'envirobot',\n",
       " 'ainsi',\n",
       " 'snowscience',\n",
       " 'sensors',\n",
       " 'medicine',\n",
       " 'proteins',\n",
       " 'series',\n",
       " 'waste',\n",
       " 'encore',\n",
       " 'alpine',\n",
       " 'extreme',\n",
       " 'portable',\n",
       " 'artlab',\n",
       " 'pierresoulages',\n",
       " 'points',\n",
       " 'different',\n",
       " 'bci',\n",
       " 'awards',\n",
       " 'champions',\n",
       " 'directeur',\n",
       " 'dune',\n",
       " 'humaines',\n",
       " 'measurements',\n",
       " 'tip',\n",
       " 'imaging',\n",
       " 'espace',\n",
       " 'avant',\n",
       " '√©dition',\n",
       " 'avril',\n",
       " 'comes',\n",
       " 'travaux',\n",
       " 'stanford',\n",
       " 'spy',\n",
       " 'bbc',\n",
       " 'technologisteu',\n",
       " 'dhums',\n",
       " 'carlo',\n",
       " 'sept',\n",
       " 'review',\n",
       " 'sustainable',\n",
       " 'fast',\n",
       " 'espdakar',\n",
       " 'verge',\n",
       " 'datajamdays',\n",
       " 'ar',\n",
       " 'venez',\n",
       " 'patrimoine',\n",
       " 'reportage',\n",
       " 'fran√ßais',\n",
       " 'months',\n",
       " 'techcrunch',\n",
       " 'lereseau',\n",
       " 'try',\n",
       " 'propos√©',\n",
       " 'field',\n",
       " 'oui',\n",
       " 'chimie',\n",
       " 'isbsib',\n",
       " 'thursday',\n",
       " 'inscription',\n",
       " 'temps',\n",
       " 'resistance',\n",
       " 'microscopy',\n",
       " 'startuptickerch',\n",
       " 'discuss',\n",
       " 'artificialintelligence',\n",
       " 'itfaconference',\n",
       " 'v',\n",
       " 'behind',\n",
       " 'approach',\n",
       " 'matin',\n",
       " 'currently',\n",
       " 'wish',\n",
       " '√ºber',\n",
       " 'sharing',\n",
       " 'scala',\n",
       " 'gr√§tzel',\n",
       " 'practical',\n",
       " 'specialist',\n",
       " 'academia',\n",
       " 'three',\n",
       " 'times',\n",
       " 'behavior',\n",
       " 'concours',\n",
       " 'epflmaurice',\n",
       " 'mauricelibrarysecurity',\n",
       " 'additive',\n",
       " 'photograph',\n",
       " 'birthday',\n",
       " 'vusurlecampus',\n",
       " 'active',\n",
       " 'shared',\n",
       " 'abstract',\n",
       " 'submission',\n",
       " 'touch',\n",
       " 'jmlattes',\n",
       " 'regisgodec',\n",
       " 'autatetoulouse',\n",
       " 'type',\n",
       " 'probably',\n",
       " 'harvardmed',\n",
       " 'museomix',\n",
       " 'candidatures',\n",
       " 'winter',\n",
       " 'improves',\n",
       " 'chromatin',\n",
       " 'digitalday',\n",
       " 'programmation',\n",
       " 'classe',\n",
       " 'drivers',\n",
       " 'kickoff',\n",
       " 'pm',\n",
       " 'graphene',\n",
       " 'create',\n",
       " 'truly',\n",
       " 'anton',\n",
       " 'schleiss',\n",
       " 'jours',\n",
       " 'deux',\n",
       " 'promising',\n",
       " 'modular',\n",
       " 'origami',\n",
       " 'ieee',\n",
       " 'received',\n",
       " 'suivre',\n",
       " 'looks',\n",
       " 'awesome',\n",
       " 'places',\n",
       " 'reconstruction',\n",
       " 'juridiques',\n",
       " 'rehabilitation',\n",
       " 'registration',\n",
       " 'built',\n",
       " 'species',\n",
       " 'ones',\n",
       " 'paris',\n",
       " 'set',\n",
       " 'aceexpedition',\n",
       " 'ethz',\n",
       " 'weeks',\n",
       " 'seed',\n",
       " 'industry',\n",
       " 'opening',\n",
       " 'job',\n",
       " 'stratocore',\n",
       " 'geomechaepfl',\n",
       " 'geteschool',\n",
       " 'management',\n",
       " 'cloud',\n",
       " 'lors',\n",
       " 'opticalfiber',\n",
       " 'succ√®s',\n",
       " 'martin',\n",
       " 'vetterli',\n",
       " 'app',\n",
       " 'aus',\n",
       " 'opendatach',\n",
       " 'christmas',\n",
       " 'together',\n",
       " 'featuring',\n",
       " 'value',\n",
       " 'camp',\n",
       " 'bring',\n",
       " 'case',\n",
       " 'skills',\n",
       " 'e',\n",
       " 'swissedtech',\n",
       " 'feedback',\n",
       " 'enhances',\n",
       " 'brainwave',\n",
       " 'handexoskeleton',\n",
       " 'september',\n",
       " 'assist',\n",
       " 'patrick',\n",
       " 'aebischer',\n",
       " 'soir',\n",
       " 'repair',\n",
       " 'tissue',\n",
       " 'pain',\n",
       " 'gamayanews',\n",
       " 'break',\n",
       " 'pump',\n",
       " 'r√©f√©rences',\n",
       " 'filles',\n",
       " 'highway',\n",
       " 'dindin',\n",
       " 'starting',\n",
       " 'unique',\n",
       " 'humanitarian',\n",
       " 'progress',\n",
       " 'getting',\n",
       " 'soon',\n",
       " 'jchenal',\n",
       " 'tdgch',\n",
       " 'focusonline',\n",
       " 'bild',\n",
       " 'regierungbw',\n",
       " 'cdu',\n",
       " 'gruenebundestag',\n",
       " 'thomasoppermann',\n",
       " 'gruenebw',\n",
       " 'europarlen',\n",
       " 'thats',\n",
       " 'pitch',\n",
       " 'news',\n",
       " 'patterns',\n",
       " 'transform',\n",
       " 'furniture',\n",
       " 'kamiahok',\n",
       " 'microsoft',\n",
       " 'bradsmi',\n",
       " 'ebugnion',\n",
       " 'geneve',\n",
       " 'donc',\n",
       " 'cette',\n",
       " 'archives',\n",
       " 'members',\n",
       " 'including',\n",
       " 'scientific',\n",
       " 'reveals',\n",
       " 'aviation',\n",
       " 'zhaw',\n",
       " 'facebook',\n",
       " 'versatile',\n",
       " 'countries',\n",
       " 'cltucci',\n",
       " 'pr√©sentation',\n",
       " 'registered',\n",
       " 'mati√®re',\n",
       " 'stress',\n",
       " 'cyclometalated',\n",
       " 'ruthenium',\n",
       " 'directly',\n",
       " 'leader',\n",
       " 'giving',\n",
       " 'kicking',\n",
       " 'tutorial',\n",
       " 'timeseries',\n",
       " 'identified',\n",
       " 'gene',\n",
       " 'heclausanne',\n",
       " 'trois',\n",
       " '√©tudier',\n",
       " 'observed',\n",
       " 'weather',\n",
       " 'antarctica',\n",
       " 'ict',\n",
       " 'conf',\n",
       " 'platforms',\n",
       " 'capitale',\n",
       " 'kuka',\n",
       " 'setzt',\n",
       " 'trusting',\n",
       " 'asks',\n",
       " 'sait',\n",
       " 'etatdevaud',\n",
       " 'national',\n",
       " 'dynamics',\n",
       " 'mechanisms',\n",
       " 'transformtech',\n",
       " 'imd',\n",
       " 'mrhiura',\n",
       " 'avoid',\n",
       " 'everyone',\n",
       " 'board',\n",
       " 'gender',\n",
       " 'strategy',\n",
       " 'childcare',\n",
       " 'trekkinglemon',\n",
       " 'lextensoetudian',\n",
       " 'fait',\n",
       " 'swisscom',\n",
       " 'd√©fis',\n",
       " 'tout',\n",
       " 'citation',\n",
       " 'produce',\n",
       " 'dtsbourg',\n",
       " 'informed',\n",
       " 'nucleosomes',\n",
       " 'micro',\n",
       " 'histone',\n",
       " 'dynamic',\n",
       " 'jan',\n",
       " 'talks',\n",
       " 'small',\n",
       " 'existing',\n",
       " 'revolutionize',\n",
       " 'lire',\n",
       " 'louvrir',\n",
       " 'secret',\n",
       " 'archimagredac',\n",
       " 'challenges',\n",
       " 'r',\n",
       " 'dtutweet',\n",
       " 'leukemia',\n",
       " 'clearer',\n",
       " 'woop',\n",
       " 'covestrogroup',\n",
       " 'imdeanano',\n",
       " 'ujinoticias',\n",
       " 'imperialcollege',\n",
       " 'irem',\n",
       " 'winning',\n",
       " 'hot',\n",
       " 'geothermal',\n",
       " 'scireports',\n",
       " 'chance',\n",
       " 'deconvolution',\n",
       " 'deconvolutionlab',\n",
       " 'results',\n",
       " 'act',\n",
       " 'selfsufficient',\n",
       " 'home',\n",
       " 'panels',\n",
       " 'solardecathlon',\n",
       " 'advanced',\n",
       " 'ht',\n",
       " 'surface',\n",
       " 'nano',\n",
       " 'ex',\n",
       " 'member',\n",
       " 'discovery',\n",
       " 'century',\n",
       " 'jet',\n",
       " 'lag',\n",
       " 'chiccommunity',\n",
       " 'eye',\n",
       " 'architect']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Construct the term document matrix\n",
    "In this question, you need to construct the term document matrix given the vocabulary and the set of documents.\n",
    "The value of a cell (i, j) is the term frequency of the term i in document j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_term_document_matrix(vocabulary, documents):\n",
    "    # Construct term-doc matrix\n",
    "    matrix = np.zeros((len(vocabulary), len(documents)))\n",
    "    for j, document in enumerate(documents):\n",
    "        counter = Counter(document.split())\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            if word in counter:\n",
    "                matrix[i,j] = counter[word]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix_freq = construct_term_document_matrix(vocab_freq, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Perform LSI by selecting the first 100 largest singular values of the term document matrix  \n",
    "Hint 1: np.linalg.svd(M, full_matrices=False) performs SVD on the matrix $\\mathbf{M}$ and returns $\\mathbf{K}, \\mathbf{S}, \\mathbf{D}^T$\n",
    "\n",
    " -  $\\mathbf{K}, \\mathbf{D}^T$ are matrices with orthonormal columns\n",
    " -  $\\mathbf{S}$ is a **vector** of singular values in a **descending** order\n",
    " \n",
    "Hint 2: np.diag(V) converts a vector to a diagonal matrix\n",
    "\n",
    "Hint 3: To select \n",
    " - The first k rows of a matrix A, use A[0:k, :]\n",
    " - The first k columns of a matrix A, use A[:, 0:k]\n",
    " - The submatrix from first k rows and k columns of a matrix A, use A[0:k, 0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_svd(term_doc_matrix, num_val):\n",
    "    K, S, Dt = np.linalg.svd(term_doc_matrix, full_matrices=False)\n",
    "    K_sel = K[:,0:num_val]\n",
    "    S_sel = np.diag(S)[0:num_val,0:num_val]\n",
    "    Dt_sel = Dt[0:num_val,:]\n",
    "    return K_sel, S_sel, Dt_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_freq, S_freq, Dt_freq = truncated_svd(term_doc_matrix_freq,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Transform the given query\n",
    "In this question, you need to construct a vector representation for the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['epfl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_document_vector(query, vocabulary):\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    for word in query:\n",
    "        try:\n",
    "            vector[vocabulary.index(word)] += 1\n",
    "        except: # if query word is not in vocabulary\n",
    "            # ignore it\n",
    "            pass\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: \n",
    " -  To compute inverse of a matrix M, use np.linalg.inv(M)\n",
    " -  To compute the dot product of A, B, use np.dot(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_query_vector(query, vocabulary, K_sel, S_sel):\n",
    "    q = query_to_document_vector(query, vocabulary)\n",
    "    mapper = np.dot(K_sel, np.linalg.inv(S_sel))\n",
    "    q_trans =  np.dot( q, mapper)\n",
    "    return q_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector_freq = construct_query_vector(query, vocab_freq, K_freq, S_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Retrieve top-10 relevant documents\n",
    "In this question, you need to retrieve the top-10 documents that are relevant to the query using cosine similarity. You are given a function to compute the cosine simimlarity and a function that return the top-k documents given the query and document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy*1.0/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query_vector, top_k, Dt_sel):\n",
    "    scores = [[cosine_similarity(query_vector, Dt_sel[:,d]), d] for d in range(len(documents))]\n",
    "    scores.sort(key=lambda x: -x[0])\n",
    "    doc_ids = []\n",
    "    retrieved = []\n",
    "    for i in range(top_k):\n",
    "        doc_ids.append(scores[i][1])\n",
    "        retrieved.append(orig_docs[scores[i][1]])\n",
    "    return doc_ids, retrieved\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qh/45t3t2ws29984shqtr0d7wgh0000gn/T/ipykernel_1377/2486228715.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return sumxy*1.0/math.sqrt(sumxx*sumyy)\n"
     ]
    }
   ],
   "source": [
    "retrieved_ids_freq, retrieved_docs_freq = retrieve_documents(query_vector_freq, 10, Dt_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@EPFL Retrouvez votre 1er tweet s√©lectionn√© par L'important \"\n",
      " 'https://t.co/B2tCt924Cp\\n',\n",
      " 'Environnement, un march√© en pleine croissance https://t.co/ThTcYLrMtn Avec '\n",
      " 'Philippe Thalmann @EPFL\\n',\n",
      " \"Belle le√ßon de technologie dans @RTScqfd avec l'exosquelette \"\n",
      " '@twiice_official test√© par Silke Pan. https://t.co/4uIdXckvaq #RTScqfd '\n",
      " '#EPFL\\n',\n",
      " 'Chocolate &amp; berries #vegan cheesecake for my @EPFL coworkers! ‚úåüèΩüå± '\n",
      " '#veganfood #EPFLfood https://t.co/wPlLsIt0KD\\n',\n",
      " \"L'app pour ¬´liker¬ª en direct les transports publics https://t.co/3HbkTnIE3Q \"\n",
      " '#epfl\\n',\n",
      " 'sign√© @EPFL https://t.co/sRldB2O7PM\\n',\n",
      " \"L'√©lectrochimie d√©busque les prot√©ines r√©sistantes aux antibiotiques \"\n",
      " 'https://t.co/BHlj5WHMbC Avec Hubert Girault @EPFL\\n',\n",
      " '#ff @Kikohs and his beautiful artworks. Some of them are displayed at @EPFL '\n",
      " 'and featured on ZettaBytes! https://t.co/8F4BNL7aAs\\n',\n",
      " 'Ca court, ca court √† #carandache #epfl #wwim15 #wwim15_igerslausanne '\n",
      " 'https://t.co/0bNMBPx50k\\n',\n",
      " 'Femmes en politique, pour en finir avec les seconds r√¥les '\n",
      " 'https://t.co/IgIkg8yrxy #epfl\\n']\n"
     ]
    }
   ],
   "source": [
    "pprint(retrieved_docs_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2: Evaluation\n",
    "In this question, we consider the scikit reference code as an ‚Äúoracle‚Äù that supposedly gives the correct result. You need to compare your retrieval results with this oracle using the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval oracle \n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), vocabulary=vocab_freq, min_df = 1, stop_words = 'english')\n",
    "features = tf.fit_transform(documents)\n",
    "npm_tfidf = features.todense()\n",
    "\n",
    "# Return all document ids that that have cosine similarity with the query larger than a threshold\n",
    "def search_vec_sklearn(query, features, threshold=0.3):\n",
    "    new_features = tf.transform([query])\n",
    "    cosine_similarities = linear_kernel(new_features, features).flatten()\n",
    "    related_docs_indices, cos_sim_sorted = zip(*sorted(enumerate(cosine_similarities), key=itemgetter(1), \n",
    "                                                       reverse=True))\n",
    "    doc_ids = []\n",
    "    for i, cos_sim in enumerate(cos_sim_sorted):\n",
    "        if cos_sim < threshold:\n",
    "            break\n",
    "        doc_ids.append(related_docs_indices[i])\n",
    "    return doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = search_vec_sklearn(\" \".join(query), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@EPFL Retrouvez votre 1er tweet s√©lectionn√© par L'important https://t.co/B2tCt924Cp\n",
      "Environnement, un march√© en pleine croissance https://t.co/ThTcYLrMtn Avec Philippe Thalmann @EPFL\n",
      "Belle le√ßon de technologie dans @RTScqfd avec l'exosquelette @twiice_official test√© par Silke Pan. https://t.co/4uIdXckvaq #RTScqfd #EPFL\n",
      "Chocolate &amp; berries #vegan cheesecake for my @EPFL coworkers! ‚úåüèΩüå± #veganfood #EPFLfood https://t.co/wPlLsIt0KD\n",
      "L'app pour ¬´liker¬ª en direct les transports publics https://t.co/3HbkTnIE3Q #epfl\n",
      "I see you @EPFL ! https://t.co/BxrHPaMqlX\n",
      "#Walking on two #legs isn‚Äôt as easy as it seems... @EPFL  https://t.co/Af6Shy2CvV https://t.co/ecz2M8Znl4\n",
      "sign√© @EPFL https://t.co/sRldB2O7PM\n",
      "L'√©lectrochimie d√©busque les prot√©ines r√©sistantes aux antibiotiques https://t.co/BHlj5WHMbC Avec Hubert Girault @EPFL\n",
      "#ff @Kikohs and his beautiful artworks. Some of them are displayed at @EPFL and featured on ZettaBytes! https://t.co/8F4BNL7aAs\n",
      "Ca court, ca court √† #carandache #epfl #wwim15 #wwim15_igerslausanne https://t.co/0bNMBPx50k\n",
      "Femmes en politique, pour en finir avec les seconds r√¥les https://t.co/IgIkg8yrxy #epfl\n",
      "Le camion Cargo Congo du @theatredevidy est sur la #PlaceCosandey- ne manquez pas de venir d√©couvrir ce spectacle de 10 mins jusqu‚Äô√† 14h puis √† 16h @EPFL https://t.co/D2JZztA3Ca\n",
      "Un Plan de mobilit√© ¬´ Made in EPFL ¬ª https://t.co/efcVQ215Nh #epfl\n",
      "Des #microchips optimisent les ¬´codes polaires¬ª essentiels √† la #5G https://t.co/FS7tDPBFsP @epfl\n",
      "Attention aux emails frauduleux https://t.co/Mjlq4D3RWM #epfl\n",
      "Des nichoirs digitaux pour observer les chouettes https://t.co/iPc3bFDrsL Avec Marion Curdy @EPFL\n",
      "#Melenchon passe 2eme dans l'outils d'analyse des #reseauxsociaux de @SwissquoteNews @EPFL  https://t.co/gQk1H9bPlR #Presidentielle2017 https://t.co/qFNRPQE4t2\n",
      "Les #GAFA sont-ils devenus trop puissants? https://t.co/9F9q98oXPE Avec Charles Wyplosz @IHEID et Denis Gillet @EPFL\n",
      "But what a woman! @samsam_86 #EPFL   https://t.co/hM1ccY2plN\n",
      "L'histoire de l'Acad√©mie racont√©e par #Jean-ClaudeBadoux, seul pr√©sident romand de la SATW jusqu'√† pr√©sent: https://t.co/yRkOycBSle @EPFL https://t.co/ZZXZHasdjN\n",
      "Que reste-t-il de l πesprit des squats des ann√©es 1980?  https://t.co/m80VlQSkfQ Avec Luca Pattaroni @EPFL\n",
      "EPFL morning #epfl #lausanne #photography https://t.co/6IXddicblu\n",
      "PostCarWorld | EPFL https://t.co/KfFQRJrQVb #epfl #epflcampus\n",
      "Bluebrain | EPFL https://t.co/Y2S3hz1817 #epfl #epflcampus\n",
      "Six EPFL startups are among the Swiss top 10 https://t.co/Re0xB2VBZ0 #epfl\n",
      "EPFL students get hands-on experience with ‚ÄúMade in China‚Äù https://t.co/DKgMXia7tQ #epfl\n",
      "Spaceship #epfl #lausanne https://t.co/Lb223yT804\n",
      "L'√©lectrochimie d√©busque les prot√©ines r√©sistantes aux antibiotiques via @EPFL #VDtech https://t.co/r9bSbXeLCB\n",
      "Waiting for the ceremony to start! #epflalumnigala #epfl  @epfl https://t.co/ucZjZmNfYF\n",
      "Deprivation: a decisive factor in genetic predisposition to #obesity a study @EPFL @CHUVLausanne https://t.co/epvU8vlA0c #epfl #publichealth https://t.co/jW8sWVTLTQ\n",
      "Nicolas Mounet from EPFL @EPFL talking about two-dimensional materials and high-throughput calculations at #MaXConf2018 in Trieste @aiidateam @nccr_marvel https://t.co/qGyOt0yVZn\n",
      "Drone Days | EPFL https://t.co/ZdNwhb0EzL #epfl #epflcampus\n",
      "Le myst√®re Soulages √©blouit la science @EPFL  https://t.co/u3uNICyAdi\n",
      "Functional programming in @scala_lang @epfl first day https://t.co/HTryOqhYq7\n"
     ]
    }
   ],
   "source": [
    "for i in gt_ids:\n",
    "    print(orig_docs[i].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Compute F1-score at 10 between the oracle and your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_at_k(predict, gt, k):\n",
    "    correct_recall = set(predict[:k]).intersection(set(gt))\n",
    "    return len(correct_recall)/len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_at_k(predict, gt, k):\n",
    "    correct_predict = set(predict[:k]).intersection(set(gt))\n",
    "    return len(correct_predict)/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(predict, gt, k):\n",
    "    prec = compute_precision_at_k(predict, gt, k)\n",
    "    rec = compute_recall_at_k(predict, gt, k)\n",
    "    print(prec, rec)\n",
    "    return 2*prec*rec/(prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.2857142857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4444444444444445"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score(retrieved_ids_freq, gt_ids, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3. Visualization\n",
    "Plot the terms using two principal concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Compute the term vectors using two principal concepts\n",
    "Hint: you can reuse a method from the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_vecs_freq, _, _ = truncated_svd(term_doc_matrix_freq,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_vecs_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You can use plt.scatter(x, y) for a scatter plot. x is a vector of x-axis value and y is a vector of y-axis value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(term_vecs_freq[:, 0], term_vecs_freq[:, 1])\n",
    "for i, t in enumerate(vocab_freq):\n",
    "    plt.annotate(t, (term_vecs_freq[i, 0], term_vecs_freq[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Explain the scatter plot of the term vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epfl and epflen are two Twitter handles of EPFL which explains why the two principal concepts are mainly made up of these terms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "75fd394e35225182f207b93437350142e41aafd8fa2b11cc1a17258e1fa2f196"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
